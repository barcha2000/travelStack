{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab1734c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T10:49:54.562709100Z",
     "start_time": "2024-02-10T10:49:54.537753700Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, RandomForestClassificationSummary, RandomForestClassificationModel, NaiveBayes, GBTClassifier,FMClassifier\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler, ChiSqSelector, PCA\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0df13f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:45:02.409311700Z",
     "start_time": "2024-02-10T09:45:02.335280100Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b810bd",
   "metadata": {},
   "source": [
    "# Projekt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d026e6c",
   "metadata": {},
   "source": [
    "W niniejszej analizie weźmiemy pod uwagę dane Travel z bazy danych StackOverflow. Ogólny zamysł tego zbioru danych polega na pytaniach oraz odpowiedziach użytkowników na temat podróżowania oraz turystyki wraz ze wszystkimi szczegółami.\n",
    "\n",
    "Skupimy się na trzech tabelach takich jak Posts, Users oraz Tags. Wybierzemy te zmienne, które będą pasowały do specyfiki projektu oraz przydadzą się w modelowaniu i analizie. Dodatkowo stworzymy własne zmienne w celu ułatwienia stworzenia klasyfikatorów. Naszym zadaniem będzie zbudowanie modelu przewidującego, czy na dane pytanie zostanie udzielona zaakceptowana odpowiedź. Poniżej umieszczamy opis zmiennych, które weźmiemy pod uwagę w analizie."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tabela Posts (22 kolumn, 128164 wierszy)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c79af79f137b3e94"
  },
  {
   "cell_type": "markdown",
   "id": "f73f2d9c",
   "metadata": {},
   "source": [
    "Zawiera głównie informacje na temat nieusuniętych pytań oraz odpowiedzi. W naszym przypadku będziemy brali pod uwagę tylko pytania oraz poniższe zmienne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362c3a5",
   "metadata": {},
   "source": [
    "- Id (identyfikator posta),\n",
    "- PostTypeId (1 = Pytanie, 2 = Odpowiedź),\n",
    "- AcceptedAnswerId (identyfikator zaakceptowanej odpowiedzi),\n",
    "- CreationDate (data utworzenia),\n",
    "- ClosedDate (data zamknięcia),\n",
    "- Score (różnica pomiędzy pozytywnymi, a negatywnymi reakcjami pod postem),\n",
    "- Body (treść posta),\n",
    "- OwnerUserId (numer identyfikacyjny twórcy),\n",
    "- Tags (tagi umieszczone w pytaniu),\n",
    "- CommentCount (ilość komentarzy),\n",
    "- Title (tytuł pytania),\n",
    "- ViewCount (liczba wyświetleń)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee4c89",
   "metadata": {},
   "source": [
    "### Tabela Users (12 kolumn, 105401 wierszy)\n",
    "zawiera liczne informacje odnośnie użytkowników portalu StackOverflow. Zmienne, które wykorzystamy w projekcie:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08531da3",
   "metadata": {},
   "source": [
    "- Id (identyfikator),\n",
    "- Location (lokalizacja użytkownika),\n",
    "- UpVotes (liczba pozytywnych reakcji jakie otrzymał użytkownik),\n",
    "- Views (liczba wyświetleń profilu użytkownika)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b3368",
   "metadata": {},
   "source": [
    "### Tabela Posts (5 kolumn, 1954 wierszy)\n",
    "Posłuży nam ona jedynie do znalezienia najpopularniejszych tagów wykorzystując zmienną TagName i zliczając ilość wystąpień każdego tagu w tabeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55d64a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:46:11.489971400Z",
     "start_time": "2024-02-10T09:45:02.396731300Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Travel\").config(\"spark.jars.packages\",\"com.databricks:spark-xml_2.12:0.17.0\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2567efa0",
   "metadata": {},
   "source": [
    "Tworzymy trzy ramki danych ze zbioru TravelStack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da93eab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:00.562331500Z",
     "start_time": "2024-02-10T09:46:11.493186900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_posts = spark.read.format(\"com.databricks.spark.xml\").option(\"rowTag\", \"row\").option(\"rootTag\", \"posts\").load(\"../data/posts.xml\")\n",
    "df_users = spark.read.format(\"com.databricks.spark.xml\").option(\"rowTag\", \"row\").option(\"rootTag\", \"users\").load(\"../data/users.xml\")\n",
    "df_tags = spark.read.format(\"com.databricks.spark.xml\").option(\"rowTag\", \"row\").option(\"rootTag\", \"tags\").load(\"../data/tags.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd68b9",
   "metadata": {},
   "source": [
    "Poniżej przygotujemy funkcje, które będą pomocne przy tworzeniu nowych kolumn w naszych danych:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44057458",
   "metadata": {},
   "source": [
    "Funkcja if_NaN zwraca 1, gdy wartość wejściowa nie jest wartością brakującą (NaN), a 0 w przeciwnym przypadku. Użyjemy jej do określenia, czy pytanie posiada zaakceptowaną odpowiedź (zmienna AcceptedAnswerId)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79834f88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:01.254862300Z",
     "start_time": "2024-02-10T09:47:00.588725800Z"
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType='int')\n",
    "def if_NaN(x):\n",
    "    if x is not None:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5168938c",
   "metadata": {},
   "source": [
    "Funkcja slen przyjmuje argument typu string, oblicza długość ciągu znaków i zwraca tę wartość jako liczbę całkowitą. Użyjemy jej dla kolumn Body i Title, aby uczynić je bardziej przydatnymi w modelowaniu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff602b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:01.436863200Z",
     "start_time": "2024-02-10T09:47:01.278865100Z"
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType='int') \n",
    "def slen(s):\n",
    "    return len(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82fa25d",
   "metadata": {},
   "source": [
    "Funkcja if_Tag sprawdza, czy dany tag znajduje się w kolumnie Tags. Jeśli tag jest obecny w ciągu znaków, funkcja zwraca 1, w przeciwnym razie zwraca 0. Bierzemy pod uwagę pięć najpopularniejszych tagów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1def7f3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:01.839864700Z",
     "start_time": "2024-02-10T09:47:01.481861700Z"
    }
   },
   "outputs": [],
   "source": [
    "@udf(returnType='int')\n",
    "def if_Tag1(x):\n",
    "    tag = \"<\" + popular_tags[0][0] + \">\"\n",
    "    if tag in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "@udf(returnType='int')\n",
    "def if_Tag2(x):\n",
    "    tag = \"<\" + popular_tags[1][0] + \">\"\n",
    "    if tag in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "@udf(returnType='int')\n",
    "def if_Tag3(x):\n",
    "    tag = \"<\" + popular_tags[2][0] + \">\"\n",
    "    if tag in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "@udf(returnType='int')\n",
    "def if_Tag4(x):\n",
    "    tag = \"<\" + popular_tags[3][0] + \">\"\n",
    "    if tag in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "@udf(returnType='int')\n",
    "def if_Tag5(x):\n",
    "    tag = \"<\" + popular_tags[4][0] + \">\"\n",
    "    if tag in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433d19a",
   "metadata": {},
   "source": [
    "Korzystając z tabeli Tags, znajdujemy najpopularniejsze tagi i przypisujemy je do zmiennej popular_tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec24633b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:07.056412500Z",
     "start_time": "2024-02-10T09:47:01.846481900Z"
    }
   },
   "outputs": [],
   "source": [
    "popular_tags = df_tags.select(df_tags._TagName).sort(\"_Count\", ascending = False).limit(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d868a84",
   "metadata": {},
   "source": [
    "Zaktualizowana ramka danych \"Posts\":\n",
    "- zawiera tylko pytania (PostTypeId = 1),\n",
    "- ma kolumnę logiczną AcceptedAnswerExist (1, jeśli istnieje, 0, jeśli brak danych),\n",
    "- zawiera długość treści w kolumnach Body i Title,\n",
    "- posiada kolumnę logiczną IfClosed (1, jeśli pytanie jest zamknięte, 0, jeśli jeszcze nie),\n",
    "- posiada nowe kolumny (typu bool), które określają, czy pytanie ma adekwatny tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc120fe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:07.969427300Z",
     "start_time": "2024-02-10T09:47:07.062429900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_posts_updated = df_posts.select(if_NaN(\"_AcceptedAnswerId\").alias(\"AcceptedAnswerExist\"), df_posts._AnswerCount,\n",
    "slen(\"_Body\").alias(\"BodyLen\"), df_posts._CommentCount, df_posts._CreationDate, if_NaN(\"_ClosedDate\").alias(\"IfClosed\"),\n",
    "df_posts._Id, df_posts._OwnerUserId, df_posts._PostTypeId, df_posts._Score, df_posts._Tags, slen(\"_Title\").alias(\"TitleLen\"),\n",
    "df_posts._ViewCount) \\\n",
    ".withColumn(\"TagVisas\",if_Tag1(\"_Tags\")) \\\n",
    ".withColumn(\"TagUsa\", if_Tag2(\"_Tags\")) \\\n",
    ".withColumn(\"TagUk\", if_Tag3(\"_Tags\")) \\\n",
    ".withColumn(\"TagAir-travel\", if_Tag4(\"_Tags\")) \\\n",
    ".withColumn(\"TagCustoms-and-immigration\", if_Tag5(\"_Tags\")) \\\n",
    ".filter(\"_PostTypeId == 1\") \\\n",
    ".filter(\"_OwnerUserId NOT LIKE 'NaN' \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ce1b73",
   "metadata": {},
   "source": [
    "Zaktualizowana ramka danych \"Users\":\n",
    "- zawiera tylko kolumny Id, Location, UpVotes oraz Views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b8a1041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:08.219622500Z",
     "start_time": "2024-02-10T09:47:08.036657200Z"
    }
   },
   "outputs": [],
   "source": [
    "df_users_new = df_users.select(\"_Id\", \"_Location\", \"_UpVotes\", \"_Views\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf91c18",
   "metadata": {},
   "source": [
    "Łączenie wcześniej stworzonych tabel \"Posts\" oraz \"Users\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e2dc5fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:08.609595100Z",
     "start_time": "2024-02-10T09:47:08.242461700Z"
    }
   },
   "outputs": [],
   "source": [
    "df_main = df_posts_updated.join(df_users_new, df_posts_updated._OwnerUserId == df_users_new._Id, 'left_outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b354bc",
   "metadata": {},
   "source": [
    "Poniżej przedstawiamy gotową do analizy tabelę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "290b2cdd",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:58.776956800Z",
     "start_time": "2024-02-10T09:47:08.617529600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       AcceptedAnswerExist  _AnswerCount  BodyLen  _CommentCount  \\\n0                        1             3      504              3   \n1                        1             2     1034              0   \n2                        0             4     1399              4   \n3                        1             5      908              0   \n4                        1             3     1961              1   \n...                    ...           ...      ...            ...   \n46740                    0             0      206              4   \n46741                    0             0      634              0   \n46742                    1             1      516              7   \n46743                    0             0      670              7   \n46744                    0             2      235              4   \n\n                _CreationDate  IfClosed     _Id  _OwnerUserId  _PostTypeId  \\\n0     2011-06-21 22:30:38.687         0       8            26            1   \n1     2011-07-03 13:21:51.543         0     780            26            1   \n2     2011-07-05 23:19:11.723         0     823            26            1   \n3     2011-07-09 22:26:20.707         0     886            26            1   \n4     2011-07-10 21:07:46.663         0     910            26            1   \n...                       ...       ...     ...           ...          ...   \n46740 2023-10-05 06:18:47.033         0  183941        139575            1   \n46741 2023-11-16 14:36:11.810         1  184610        140604            1   \n46742 2023-05-04 12:45:11.337         0  180981        135572            1   \n46743 2023-06-18 12:15:38.257         0  181833        136645            1   \n46744 2023-07-14 15:34:07.200         0  182368        137306            1   \n\n       _Score  ... _ViewCount  TagVisas  TagUsa  TagUk  TagAir-travel  \\\n0          15  ...      12989         0       0      0              0   \n1          26  ...       6276         0       0      1              0   \n2          10  ...       1742         0       0      0              0   \n3          17  ...      10271         0       0      0              0   \n4           6  ...       1857         0       0      0              0   \n...       ...  ...        ...       ...     ...    ...            ...   \n46740       4  ...        133         0       0      0              0   \n46741       2  ...         48         1       0      0              0   \n46742       0  ...        161         0       0      0              0   \n46743       1  ...        159         0       0      0              0   \n46744       3  ...       1191         0       0      1              1   \n\n       TagCustoms-and-immigration     _Id               _Location  _UpVotes  \\\n0                               0      26  Oxford, United Kingdom     19507   \n1                               0      26  Oxford, United Kingdom     19507   \n2                               0      26  Oxford, United Kingdom     19507   \n3                               0      26  Oxford, United Kingdom     19507   \n4                               0      26  Oxford, United Kingdom     19507   \n...                           ...     ...                     ...       ...   \n46740                           0  139575                    None         0   \n46741                           0  140604                    None         0   \n46742                           0  135572                    None         0   \n46743                           1  136645                    None         0   \n46744                           0  137306                    None         0   \n\n      _Views  \n0       7234  \n1       7234  \n2       7234  \n3       7234  \n4       7234  \n...      ...  \n46740      0  \n46741      0  \n46742      2  \n46743      0  \n46744      4  \n\n[46745 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AcceptedAnswerExist</th>\n      <th>_AnswerCount</th>\n      <th>BodyLen</th>\n      <th>_CommentCount</th>\n      <th>_CreationDate</th>\n      <th>IfClosed</th>\n      <th>_Id</th>\n      <th>_OwnerUserId</th>\n      <th>_PostTypeId</th>\n      <th>_Score</th>\n      <th>...</th>\n      <th>_ViewCount</th>\n      <th>TagVisas</th>\n      <th>TagUsa</th>\n      <th>TagUk</th>\n      <th>TagAir-travel</th>\n      <th>TagCustoms-and-immigration</th>\n      <th>_Id</th>\n      <th>_Location</th>\n      <th>_UpVotes</th>\n      <th>_Views</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>504</td>\n      <td>3</td>\n      <td>2011-06-21 22:30:38.687</td>\n      <td>0</td>\n      <td>8</td>\n      <td>26</td>\n      <td>1</td>\n      <td>15</td>\n      <td>...</td>\n      <td>12989</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>26</td>\n      <td>Oxford, United Kingdom</td>\n      <td>19507</td>\n      <td>7234</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>1034</td>\n      <td>0</td>\n      <td>2011-07-03 13:21:51.543</td>\n      <td>0</td>\n      <td>780</td>\n      <td>26</td>\n      <td>1</td>\n      <td>26</td>\n      <td>...</td>\n      <td>6276</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>26</td>\n      <td>Oxford, United Kingdom</td>\n      <td>19507</td>\n      <td>7234</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>4</td>\n      <td>1399</td>\n      <td>4</td>\n      <td>2011-07-05 23:19:11.723</td>\n      <td>0</td>\n      <td>823</td>\n      <td>26</td>\n      <td>1</td>\n      <td>10</td>\n      <td>...</td>\n      <td>1742</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>26</td>\n      <td>Oxford, United Kingdom</td>\n      <td>19507</td>\n      <td>7234</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>5</td>\n      <td>908</td>\n      <td>0</td>\n      <td>2011-07-09 22:26:20.707</td>\n      <td>0</td>\n      <td>886</td>\n      <td>26</td>\n      <td>1</td>\n      <td>17</td>\n      <td>...</td>\n      <td>10271</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>26</td>\n      <td>Oxford, United Kingdom</td>\n      <td>19507</td>\n      <td>7234</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1961</td>\n      <td>1</td>\n      <td>2011-07-10 21:07:46.663</td>\n      <td>0</td>\n      <td>910</td>\n      <td>26</td>\n      <td>1</td>\n      <td>6</td>\n      <td>...</td>\n      <td>1857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>26</td>\n      <td>Oxford, United Kingdom</td>\n      <td>19507</td>\n      <td>7234</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>46740</th>\n      <td>0</td>\n      <td>0</td>\n      <td>206</td>\n      <td>4</td>\n      <td>2023-10-05 06:18:47.033</td>\n      <td>0</td>\n      <td>183941</td>\n      <td>139575</td>\n      <td>1</td>\n      <td>4</td>\n      <td>...</td>\n      <td>133</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>139575</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46741</th>\n      <td>0</td>\n      <td>0</td>\n      <td>634</td>\n      <td>0</td>\n      <td>2023-11-16 14:36:11.810</td>\n      <td>1</td>\n      <td>184610</td>\n      <td>140604</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>48</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140604</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46742</th>\n      <td>1</td>\n      <td>1</td>\n      <td>516</td>\n      <td>7</td>\n      <td>2023-05-04 12:45:11.337</td>\n      <td>0</td>\n      <td>180981</td>\n      <td>135572</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>161</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>135572</td>\n      <td>None</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>46743</th>\n      <td>0</td>\n      <td>0</td>\n      <td>670</td>\n      <td>7</td>\n      <td>2023-06-18 12:15:38.257</td>\n      <td>0</td>\n      <td>181833</td>\n      <td>136645</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>159</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>136645</td>\n      <td>None</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>46744</th>\n      <td>0</td>\n      <td>2</td>\n      <td>235</td>\n      <td>4</td>\n      <td>2023-07-14 15:34:07.200</td>\n      <td>0</td>\n      <td>182368</td>\n      <td>137306</td>\n      <td>1</td>\n      <td>3</td>\n      <td>...</td>\n      <td>1191</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>137306</td>\n      <td>None</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>46745 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f121ea3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-10T09:47:58.839399700Z",
     "start_time": "2024-02-10T09:47:58.741389700Z"
    }
   },
   "outputs": [],
   "source": [
    "df_classification = df_main.drop(\"_CreationDate\",\"_Id\",\"_OwnerUserId\",\"_PostTypeId\",\"_Tags\",\"_Location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ce9af45b0d43a3c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preoprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e28f5fe364266b21"
  },
  {
   "cell_type": "markdown",
   "source": [
    "W pierwszym kroku na naszych danych przeprowadzimy normalizacje danych numerycznych, oraz zbudujemy wektor, którym będziemy się posługiwać przy budowaniu pipelinów."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcc9384e84482dad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Poniżej przedstawiamy funkcję, która buduje i ewaluuje model w oparciu o wybrany typ klasyfikatora. Zbiór danych dzielimy na 5 części i wykonujemy na nim walidację krzyżową. Ostateczne parametry modelu są wybierane na podstawie statystyki skuteczności predykcji."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9580afab1fb62233"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def buildAndEvaluateModel(train, test, stages, classifierType, *args, **kwargs):\n",
    "    classifier = classifierType(featuresCol=\"final_features\", labelCol=\"AcceptedAnswerExist\", *args, **kwargs)\n",
    "    stages.append(classifier)\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    \n",
    "    binaryEvaluator = BinaryClassificationEvaluator(labelCol=\"AcceptedAnswerExist\", rawPredictionCol=\"rawPrediction\",\n",
    "                                                    metricName=\"areaUnderROC\")\n",
    "    multiEvaluator = MulticlassClassificationEvaluator(labelCol=\"AcceptedAnswerExist\", predictionCol=\"prediction\",\n",
    "                                                       metricName=\"accuracy\")\n",
    "    paramGrid = ParamGridBuilder().build() \n",
    "    crossval = CrossValidator(estimator=pipeline,\n",
    "                              estimatorParamMaps=paramGrid,\n",
    "                              evaluator=multiEvaluator,  \n",
    "                              numFolds=5) \n",
    "\n",
    "    cvModel = crossval.fit(train)\n",
    "    predictions = cvModel.transform(test)\n",
    "    \n",
    "    auc = binaryEvaluator.evaluate(predictions)\n",
    "    print(\"AUC:\", auc)\n",
    "    accuracy = multiEvaluator.evaluate(predictions)\n",
    "    print(\"Skuteczność:\", accuracy)\n",
    "    predictionAndLabels = predictions.select(\"prediction\", \"AcceptedAnswerExist\").rdd.map(\n",
    "        lambda row: (float(row[0]), float(row[1])))\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    confusionMatrix = metrics.confusionMatrix().toArray()\n",
    "    print(\"Macierz pomyłek:\\n\", confusionMatrix)\n",
    "    \n",
    "    TP = confusionMatrix[0, 0]\n",
    "    FN = confusionMatrix[0, 1]\n",
    "    FP = confusionMatrix[1, 0]\n",
    "    TN = confusionMatrix[1, 1]\n",
    "    \n",
    "    TPR = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    TNR = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    \n",
    "    informedness = TPR + TNR - 1\n",
    "    print(\"Informedness:\\n\", informedness)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"AUC\": auc, \"confusionMatrix\": confusionMatrix, \"Informedness\": informedness}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:34:56.978947700Z",
     "start_time": "2024-02-10T13:34:56.930951100Z"
    }
   },
   "id": "a4c4bdadee8e630b",
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def simulations(df, assembling_vectors, model_types, *args, **kwargs):\n",
    "    results = {}\n",
    "    for model in model_types:\n",
    "        train, test = df.randomSplit([0.8, 0.2])\n",
    "        stages = assembling_vectors()\n",
    "        name = model.__name__\n",
    "        print(\"\\n\\nWyniki dla \"+ name)\n",
    "        try:\n",
    "            results[name] = buildAndEvaluateModel(train, test, stages, model,  *args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Błąd: {e}\")\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T14:02:18.191496200Z",
     "start_time": "2024-02-10T14:02:18.176498Z"
    }
   },
   "id": "2eeb7f037d578cf",
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na początek przeprowadźmy symulacje dla 5 wybranych klasyfikatorów. Bedzie to regresja logistyczna, klasyfikator Factorization Machines, drzewo decyzyjne, oraz oparte na drzewach lasy losowe i Gradient Boost Trees. Przyjmujemy parametry domyślne i wszystkie kolumny naszego zbioru danych."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b91493a97994180"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Wyniki dla LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\barcha\\sparkVenv\\lib\\site-packages\\py4j\\java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"C:\\Users\\barcha\\sparkVenv\\lib\\site-packages\\py4j\\clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"C:\\Users\\barcha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Błąd dla LogisticRegression\n",
      "\n",
      "\n",
      "Wyniki dla FMClassifier\n",
      "Błąd dla FMClassifier\n",
      "\n",
      "\n",
      "Wyniki dla DecisionTreeClassifier\n",
      "Błąd dla DecisionTreeClassifier\n",
      "\n",
      "\n",
      "Wyniki dla RandomForestClassifier\n",
      "Błąd dla RandomForestClassifier\n",
      "\n",
      "\n",
      "Wyniki dla GBTClassifier\n",
      "Błąd dla GBTClassifier\n"
     ]
    }
   ],
   "source": [
    "def normalization():\n",
    "    columns_to_normalize = [\"_AnswerCount\", \"_CommentCount\", \"BodyLen\", \"_Score\", \"TitleLen\", \"_ViewCount\", \"_UpVotes\",\n",
    "                            \"_Views\"]\n",
    "    num_assembler = VectorAssembler(inputCols=columns_to_normalize, outputCol=\"numeric_features\")\n",
    "    scaler = StandardScaler(inputCol=\"numeric_features\", outputCol=\"scaled_features\")\n",
    "    \n",
    "    \n",
    "    final_columns = [\"scaled_features\", \"TagVisas\", \"TagUsa\", \"TagUk\", \"TagAir-travel\", \"TagCustoms-and-immigration\",\n",
    "                     \"IfClosed\"]\n",
    "    final_assembler = VectorAssembler(inputCols=final_columns, outputCol=\"final_features\")\n",
    "    \n",
    "    stages = [num_assembler, scaler, final_assembler]\n",
    "    return stages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:33:30.321017700Z",
     "start_time": "2024-02-10T13:24:47.051827600Z"
    }
   },
   "id": "906e64e8ab387d72",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Wyniki dla LogisticRegression\n",
      "AUC: 0.7425692459126626\n",
      "Skuteczność: 0.6894776359540921\n",
      "Macierz pomyłek:\n",
      " [[4925.  709.]\n",
      " [2186. 1503.]]\n",
      "Informedness:\n",
      " 0.28158439163222404\n",
      "\n",
      "\n",
      "Wyniki dla FMClassifier\n",
      "AUC: 0.7567089909239982\n",
      "Skuteczność: 0.6951625013407702\n",
      "Macierz pomyłek:\n",
      " [[4761.  873.]\n",
      " [1969. 1720.]]\n",
      "Informedness:\n",
      " 0.3112989398583301\n",
      "\n",
      "\n",
      "Wyniki dla DecisionTreeClassifier\n",
      "AUC: 0.7521847036248283\n",
      "Skuteczność: 0.7948085380242411\n",
      "Macierz pomyłek:\n",
      " [[4297. 1337.]\n",
      " [ 576. 3113.]]\n",
      "Informedness:\n",
      " 0.6065509305168355\n",
      "\n",
      "\n",
      "Wyniki dla RandomForestClassifier\n",
      "AUC: 0.8483989906382017\n",
      "Skuteczność: 0.7937359219135471\n",
      "Macierz pomyłek:\n",
      " [[4277. 1357.]\n",
      " [ 566. 3123.]]\n",
      "Informedness:\n",
      " 0.6057118164865314\n",
      "\n",
      "\n",
      "Wyniki dla GBTClassifier\n",
      "AUC: 0.8624501571558576\n",
      "Skuteczność: 0.7974900783009761\n",
      "Macierz pomyłek:\n",
      " [[4341. 1293.]\n",
      " [ 595. 3094.]]\n",
      "Informedness:\n",
      " 0.6092102099007182\n"
     ]
    }
   ],
   "source": [
    "model_types = [LogisticRegression, FMClassifier, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier]\n",
    "results_of_simulations = simulations(df_classification, normalization, model_types)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T10:21:33.621288100Z",
     "start_time": "2024-02-10T09:47:59.063676900Z"
    }
   },
   "id": "a8869a1253f9c0c3",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T10:23:20.494176600Z",
     "start_time": "2024-02-10T10:23:20.456001900Z"
    }
   },
   "id": "eebc5300a44b026f",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('results.pickle', 'wb') as plik:\n",
    "    pkl.dump(results_of_simulations, plik)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T10:23:22.318729200Z",
     "start_time": "2024-02-10T10:23:22.278668200Z"
    }
   },
   "id": "8f2ec7f2e509e2ec",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def selecting_columns():\n",
    "    columns_to_normalize = [\"_AnswerCount\", \"_CommentCount\", \"BodyLen\", \"_Score\", \"TitleLen\", \"_ViewCount\", \"_UpVotes\",\n",
    "                            \"_Views\"]\n",
    "    num_assembler = VectorAssembler(inputCols=columns_to_normalize, outputCol=\"numeric_features\")\n",
    "    scaler = StandardScaler(inputCol=\"numeric_features\", outputCol=\"scaled_features\")\n",
    "    \n",
    "    \n",
    "    binaryFeatures = ['IfClosed', 'TagVisas', 'TagUsa', 'TagUk', 'TagAir-travel', 'TagCustoms-and-immigration']\n",
    "    binaryFeaturesDF = df_classification.select(*binaryFeatures, \"AcceptedAnswerExist\")\n",
    "    \n",
    "    binaryAssembler = VectorAssembler(inputCols=binaryFeatures, outputCol=\"binaryFeatures\")\n",
    "    df_binary = binaryAssembler.transform(binaryFeaturesDF)\n",
    "    \n",
    "    selector = ChiSqSelector(numTopFeatures=3, featuresCol=\"binaryFeatures\", labelCol=\"AcceptedAnswerExist\", outputCol=\"selectedBinaryFeatures\")\n",
    "    selectedBinaryFeatures = [binaryFeatures[i] for i in selector.fit(df_binary).selectedFeatures]\n",
    "    \n",
    "    final_columns = [\"scaled_features\"]\n",
    "    final_columns.extend(selectedBinaryFeatures)\n",
    "    final_assembler_selected = VectorAssembler(inputCols=final_columns, outputCol=\"final_features\")\n",
    "    \n",
    "    stages = [num_assembler, scaler, binaryAssembler, selector, final_assembler]\n",
    "    return stages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T14:02:12.971491300Z",
     "start_time": "2024-02-10T14:02:12.942475500Z"
    }
   },
   "id": "a17e35c1087b740f",
   "execution_count": 111
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Wyniki dla LogisticRegression\n",
      "AUC: 0.748041939313625\n",
      "Skuteczność: 0.6928104575163399\n",
      "Macierz pomyłek:\n",
      " [[4973.  716.]\n",
      " [2151. 1493.]]\n",
      "Informedness:\n",
      " 0.28385768248429044\n",
      "\n",
      "\n",
      "Wyniki dla FMClassifier\n",
      "AUC: 0.7592655911307917\n",
      "Skuteczność: 0.6952835188129306\n",
      "Macierz pomyłek:\n",
      " [[4869.  830.]\n",
      " [2045. 1691.]]\n",
      "Informedness:\n",
      " 0.3069835404460679\n",
      "\n",
      "\n",
      "Wyniki dla DecisionTreeClassifier\n",
      "AUC: 0.7415387111733964\n",
      "Skuteczność: 0.7915683329757562\n",
      "Macierz pomyłek:\n",
      " [[4327. 1364.]\n",
      " [ 579. 3052.]]\n",
      "Informedness:\n",
      " 0.6008631137182836\n",
      "\n",
      "\n",
      "Wyniki dla RandomForestClassifier\n",
      "AUC: 0.8509638996338359\n",
      "Skuteczność: 0.7961962394640155\n",
      "Macierz pomyłek:\n",
      " [[4295. 1316.]\n",
      " [ 570. 3073.]]\n",
      "Informedness:\n",
      " 0.608996249817706\n",
      "\n",
      "\n",
      "Wyniki dla GBTClassifier\n",
      "Błąd: An error occurred while calling o71164.evaluate.\n",
      ": org.apache.spark.SparkException: Not enough memory to build and broadcast the table to all worker nodes. As a workaround, you can either disable broadcast by setting spark.sql.autoBroadcastJoinThreshold to -1 or increase the spark driver memory by setting spark.driver.memory to a higher value.\r\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.notEnoughMemoryToBuildAndBroadcastTableError(QueryExecutionErrors.scala:2212)\r\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.$anonfun$relationFuture$1(BroadcastExchangeExec.scala:187)\r\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$1(SQLExecution.scala:223)\r\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\r\n"
     ]
    }
   ],
   "source": [
    "model_types = [LogisticRegression, FMClassifier, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier]\n",
    "results_of_simulations_selected_features = simulations(df_classification, selecting_columns, model_types)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T14:53:19.440103200Z",
     "start_time": "2024-02-10T14:02:27.523133200Z"
    }
   },
   "id": "2611554f41a1483e",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Wyniki dla GBTClassifier\n",
      "Błąd: An error occurred while calling o73227.fit.\n",
      ": org.apache.spark.SparkException: Not enough memory to build and broadcast the table to all worker nodes. As a workaround, you can either disable broadcast by setting spark.sql.autoBroadcastJoinThreshold to -1 or increase the spark driver memory by setting spark.driver.memory to a higher value.\r\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.notEnoughMemoryToBuildAndBroadcastTableError(QueryExecutionErrors.scala:2212)\r\n",
      "\tat org.apache.spark.sql.execution.exchange.BroadcastExchangeExec.$anonfun$relationFuture$1(BroadcastExchangeExec.scala:187)\r\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withThreadLocalCaptured$1(SQLExecution.scala:223)\r\n",
      "\tat java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)\r\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\r\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\r\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\r\n"
     ]
    }
   ],
   "source": [
    "model_types = [GBTClassifier]\n",
    "results_of_simulations_selected_GBT = simulations(df_classification, selecting_columns, model_types)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T14:58:03.284464400Z",
     "start_time": "2024-02-10T14:56:48.503797500Z"
    }
   },
   "id": "59902f59819d4595",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('resultsSelected.pickle', 'wb') as plik:\n",
    "    pkl.dump(results_of_simulations_selected_features, plik)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T14:54:30.195541900Z",
     "start_time": "2024-02-10T14:54:30.157547200Z"
    }
   },
   "id": "b8721aedfcf488c7",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def prepareData(df, inputCols, outputCol=\"features\", pcaK=3):\n",
    "    \n",
    "    assembler = VectorAssembler(inputCols=inputCols, outputCol=\"assembledFeatures\")\n",
    "    scaler = StandardScaler(inputCol=\"assembledFeatures\", outputCol=\"scaledFeatures\", withStd=True, withMean=True)\n",
    "    pca = PCA(k=pcaK, inputCol=\"scaledFeatures\", outputCol=outputCol)\n",
    "    \n",
    "    pipeline = Pipeline(stages=[assembler, scaler, pca])\n",
    "    transformedData = pipeline.fit(df).transform(df)\n",
    "    train, test = transformedData.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    return train, test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786e4baab29a2f6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7f22902ede562334"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wyniki"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cea2d85d4757fff3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Najpierw spójrzmy na wyniki dla modeli, które uwzględniają wszystkie zmienne, które zostały po wstępnej selekcji. Widać, że  modele oparte na drzewach są o wiele lepsze w zasadzie w każdym z kryteriów. Skuteczność i krytrium Informedness dają podobne rezultaty, choć w każdym z nich najlepsze są modele GBT. Natomiast las losowy daje wyjątkowow dużą wartość jeśli chodzi o pole pod krzywą ROC. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "582dc977534f4283"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tabela metryk, dla modelu z  uwzględnieniem wszystkich zmiennych: \n",
    "\n",
    "| Metryka     | Regresja Logistyczna | Factorial Matrix | Drzewo Decyzyjne   | Las Losowy         | Gradient-Boosted Trees  |\n",
    "|-------------|----------------------|------------------|--------------------|--------------------|-------------------------|\n",
    "| Skuteczność | 0.6895               | 0.6952           | 0.7948 | 0.7937| 0.7975                  |\n",
    "| AUC         | 0.7426 | 0.7567 | 0.7521 | 0.8484 | 0.7974                  |\n",
    "| Informedness| 0.2816 | 0.3113 | 0.6066 | 0.6057 | 0.6092                  |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "668dfda4b678adc3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29d201d1fa373722"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tabela metryk, dla modelu z wybranymi zmiennymi binarnymi: \n",
    "\n",
    "| Metryka     | Regresja Logistyczna | Factorial Matrix | Drzewo Decyzyjne   | Las Losowy | Gradient-Boosted Trees  |\n",
    "|-------------|----------------------|------------------|--------------------|------------|-------------------------|\n",
    "| Skuteczność | 0.6928               | 0.6953           | 0.7415 | 0.7962     | 0.7975                  |\n",
    "| AUC         | 0.7426 | 0.7567           | 0.7521 | 0.8484     | 0.7974                  |\n",
    "| Informedness| 0.2816 | 0.3113           | 0.6066 | 0.6057     | 0.6092                  |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2638869cf8859add"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eb7540327adf156d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "sparkvenv",
   "language": "python",
   "display_name": "sparkVenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
